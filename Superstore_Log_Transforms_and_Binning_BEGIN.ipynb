{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1YEIMX-tO7FBLN4n5z303Yw2cJrNev64D",
      "authorship_tag": "ABX9TyOvwdR2AfAfY7pV1wT+bzkY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drcochran-newman/Data-Preprocessing/blob/main/Superstore_Log_Transforms_and_Binning_BEGIN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Superstore Log Transforms and Binning\n",
        "\n",
        "**May 2025**\n",
        "\n",
        "by David Cochran\n",
        "\n",
        "[Data Science @ Newman University](https://newmanu.edu/academics/graduate-programs/ms-data-science)\n"
      ],
      "metadata": {
        "id": "BUK8R_OR81zj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries and Set Notebook Defaults"
      ],
      "metadata": {
        "id": "IC12DI0aWBbk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4MoO7Ow7yvW"
      },
      "outputs": [],
      "source": [
        "# Numpy and Pandas\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Matplotlib and Seaborn\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Jupyter Notebook customizations\n",
        "\n",
        "# Remove scientific notation from descriptive stats\n",
        "pd.options.display.float_format = '{:,.3f}'.format\n",
        "\n",
        "# Display all columns of a dataframe\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "# Widen columns\n",
        "pd.set_option('display.max_colwidth', 150)"
      ],
      "metadata": {
        "id": "2yFq9GxQRTV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Customize Seaborn Plot Styles\n",
        "\n",
        "# Adjust to retina quality\n",
        "import matplotlib_inline.backend_inline\n",
        "matplotlib_inline.backend_inline.set_matplotlib_formats(\"retina\")\n",
        "\n",
        "# Adjust dpi and font size to support high-pixel-density screens\n",
        "sns.set(rc={\"figure.dpi\":100, 'savefig.dpi':300})\n",
        "sns.set_context('notebook', font_scale = 0.8)\n",
        "\n",
        "# Display tick marks\n",
        "sns.set_style('ticks')\n",
        "\n",
        "# Remove borders\n",
        "plt.rc('axes.spines', top=False, right=False, left=False, bottom=False)\n",
        "\n",
        "# Set color palettes for plots\n",
        "# See Matplotlib named color options here: https://matplotlib.org/stable/gallery/color/named_colors.html\n",
        "blue = 'deepskyblue' # Use 'skyblue' for a lighter blue\n",
        "orange = 'orange'\n",
        "cp1 = [blue, orange]\n",
        "\n",
        "# cp2 Palette - Reversed binary color order when needed for certain plots\n",
        "cp2 = [orange, blue]\n",
        "\n",
        "# cp5 Palette - 5 colors for use with categorical data\n",
        "turquoise = 'mediumaquamarine'\n",
        "salmon = 'darksalmon'\n",
        "tan = 'tan'\n",
        "gray = 'darkgray'\n",
        "cp5 = [blue, turquoise, salmon, tan, gray]\n",
        "\n",
        "# cpd Palette - blue-to-orange diverging palette for correlation heatmaps\n",
        "cpd = sns.diverging_palette(242, 39, s=100, l=65, n=11)\n",
        "\n",
        "# Set the default palette\n",
        "sns.set_palette(cp1)"
      ],
      "metadata": {
        "id": "tvLTorttRVws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "gsdwFOygrFzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Cleaned Data"
      ],
      "metadata": {
        "id": "Nql_O3E8C7KY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read from CSV\n",
        "# Set appropriate data types\n",
        "\n",
        "# Set file path\n",
        "path = '/content/drive/MyDrive/Data Projects/Preprocessing/Superstore Preprocessing/data/Global_Superstore_Orders_2020_23.csv'\n",
        "\n",
        "# Read data\n",
        "# Set Postal Code datatype to string and fill to 5 digits with leading zeros\n",
        "superstore_cleaned_df = pd.read_csv(path, dtype={'Postal Code': str})\n",
        "\n",
        "# Fill postal codes to 5 characters with leading zeros when needed\n",
        "superstore_cleaned_df['Postal Code'] = superstore_cleaned_df['Postal Code'].str.zfill(5)\n",
        "\n",
        "# Convert dates to datetime\n",
        "superstore_cleaned_df['Order Date'] = pd.to_datetime(superstore_cleaned_df['Order Date'])\n",
        "superstore_cleaned_df['Ship Date'] = pd.to_datetime(superstore_cleaned_df['Ship Date'])\n",
        "\n",
        "superstore_cleaned_df.head()"
      ],
      "metadata": {
        "id": "Dt_mlPbdFmYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "superstore_cleaned_df.tail()"
      ],
      "metadata": {
        "id": "OEEBYu0uGPRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get number of rows and columns\n",
        "superstore_cleaned_df.shape"
      ],
      "metadata": {
        "id": "CBID5dy9MTe6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataframe fundamental info\n",
        "superstore_cleaned_df.info()"
      ],
      "metadata": {
        "id": "l9yHkGfYGVN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "superstore_cleaned_df.describe()"
      ],
      "metadata": {
        "id": "l79OTxgrhVfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "superstore_cleaned_df.describe(include='object')"
      ],
      "metadata": {
        "id": "e-pmpV7QhYBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Labels Dataframe\n",
        "\n",
        "We will create the first of two dataframes from superstore_cleaned_df:\n",
        "- Customer_Labels"
      ],
      "metadata": {
        "id": "6iIYqLjLOTOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Labels Dataframe\n",
        "# Include all records\n",
        "# Three columns: CustomerID (index), Order Date Min, and Order Date Max\n",
        "\n",
        "# Group by Customer and aggregate the Min and Max Order Date\n",
        "Customer_Labels = superstore_cleaned_df.groupby('Customer ID').agg(\n",
        "    Min_Order_Date=('Order Date', 'min'),\n",
        "    Max_Order_Date=('Order Date', 'max')\n",
        ")\n",
        "\n",
        "# Preview results\n",
        "Customer_Labels.sample(12)"
      ],
      "metadata": {
        "id": "SVUHB0RkwgsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Eliminate all Customers who did not make a purchase before 2023.**\n",
        "\n",
        "- We are only interested in customers who made a first purchase prior to 2023.\n",
        "\n",
        "- Non-churners purchased before 2023 and then made another in 2023.\n",
        "\n",
        "- Churners also purchased before 2023 but then did not return in 2023.\n",
        "\n",
        "So: Eliminate all customers from our list who made no purchases before 2023."
      ],
      "metadata": {
        "id": "zfuD7vwHx7Ws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove all customers whose Min Order Date year is 2023.\n",
        "\n",
        "Customer_Labels = Customer_Labels[Customer_Labels['Min_Order_Date'].dt.year < 2023]\n",
        "\n",
        "Customer_Labels.sample(12)\n"
      ],
      "metadata": {
        "id": "3Bxan3-qxxSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View Labels Dataframe Stats\n",
        "Customer_Labels.describe()"
      ],
      "metadata": {
        "id": "19Vwboi-Y52m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Churn Target Variable\n",
        "# If the Year of Max Order Date == 2023\n",
        "# Then Churn = 0\n",
        "# Else Churn = 1\n",
        "\n",
        "Customer_Labels['Churn'] = np.where(Customer_Labels['Max_Order_Date'].dt.year == 2023, 0, 1)\n",
        "\n",
        "Customer_Labels.head()"
      ],
      "metadata": {
        "id": "FlJhKkfBVdwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the order date fields, so that we have only Customer ID and Churn\n",
        "Customer_Labels = Customer_Labels.drop(columns=['Min_Order_Date', 'Max_Order_Date'])\n",
        "Customer_Labels.head(12)"
      ],
      "metadata": {
        "id": "DqBgcWstE2ny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare number of Churn = 1 versus Churn = 0\n",
        "Customer_Labels['Churn'].value_counts()"
      ],
      "metadata": {
        "id": "Tj8x6rnFMh7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get proportions as percentage\n",
        "Customer_Labels['Churn'].value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "2udgDdEVFOah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Features Dataframe\n",
        "\n",
        "Eliminate all records from 2023 to ensure there is no data leakage.\n",
        "\n",
        "**transaction_features** will provide the record of original transactions\n",
        "\n",
        "**Customer_Features** will aggregate the features by Customer ID and will provide the features we will need machine learning."
      ],
      "metadata": {
        "id": "1KKZow-BtoWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Features Dataframe\n",
        "# Eliminate all records from 2023 to ensure there is no data leakage\n",
        "# In this present form, it is a history of transactions, so we will name it *transaction_features*\n",
        "transaction_features = superstore_cleaned_df[superstore_cleaned_df['Order Date'] < '2023-01-01']\n",
        "transaction_features.sample(25)"
      ],
      "metadata": {
        "id": "hC_YqwhOdkjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get features dataframe info\n",
        "transaction_features.info()"
      ],
      "metadata": {
        "id": "lKiu9FgJH0s1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Double check to ensure we include NO RECORDS with Order Date in 2023\n",
        "# Get max order date of Features Dataframe\n",
        "transaction_features['Order Date'].max()"
      ],
      "metadata": {
        "id": "7FCZdF5xd4Mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRIPLE check to ensure we include NO RECORDS with Order Date in 2023\n",
        "# Sort Features Dataframe from Latest Order Date and viewing head()\n",
        "transaction_features.sort_values(by='Order Date', ascending=False).head()"
      ],
      "metadata": {
        "id": "QXsDQcN5eFuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create and Explore Numeric and Date Features\n",
        "\n",
        "We will use **transaction_features** to create **Customer_Features**.\n",
        "\n",
        "- **transaction_features** = Dataset of transactions excluding 2023 target year\n",
        "\n",
        "- **Customer_Features** = Dataset grouped by Customer ID, where we will collect our final features for machine learning"
      ],
      "metadata": {
        "id": "9hgQ53RGy6BC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Numeric Features\n",
        "1. **Transactions:** Row ID Count\n",
        "1. **Avg Quantity:** Quantity Mean\n",
        "1. **Avg Sales:** Sales Mean\n",
        "1. **Total Sales:** Sales Sum\n",
        "1. **Avg Profit:** Profit Mean\n",
        "1. **Total Profit:** Profit Sum\n",
        "1. **Avg Discount:** Discount Mean\n",
        "1. **Avg Ship Cost:** Shipping Cost Mean"
      ],
      "metadata": {
        "id": "37RnIZ6wOQ6W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Groupby Customer ID and use aggregations for the earliest Order Date, the most recent Order Date,\n",
        "# Mean Sales, Total Sales, Mean Profit, Total Profit, and a Count of all orders by each customer\n",
        "# Use the Customer ID as the new row index\n",
        "\n",
        "Customer_Features = transaction_features.groupby('Customer ID').agg(\n",
        "    Transactions=('Row ID', 'count'),\n",
        "    Avg_Quantity=('Quantity', 'mean'),\n",
        "    Avg_Sales=('Sales', 'mean'),\n",
        "    Total_Sales=('Sales', 'sum'),\n",
        "    Avg_Profit=('Profit', 'mean'),\n",
        "    Total_Profit=('Profit', 'sum'),\n",
        "    Avg_Discount=('Discount', 'mean'),\n",
        "    Avg_Ship_Cost=('Shipping Cost', 'mean')\n",
        ")\n",
        "\n",
        "# Display updated dataframe (optional)\n",
        "Customer_Features.sample(25)"
      ],
      "metadata": {
        "id": "dJX71YQodQlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explore Numeric Features\n",
        "\n",
        "**Superstore_Churn_DF** = Churn Label plus features"
      ],
      "metadata": {
        "id": "FjIpJMYHbz73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Superstore_Churn_DF = Customer_Labels.merge(Customer_Features, on='Customer ID', how='left')\n",
        "Superstore_Churn_DF.head(12)"
      ],
      "metadata": {
        "id": "hs8BrlgYcEfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Superstore_Churn_DF.info()"
      ],
      "metadata": {
        "id": "xGdjR9iAcEcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Superstore_Churn_DF.describe()"
      ],
      "metadata": {
        "id": "LvEdcId5cEZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define function to view feature distributions and statistics, grouped by target variable\n",
        "def view_distributions(data, feature, binwidth):\n",
        "\n",
        "  # Histplot\n",
        "  plt.figure(figsize=(7,3))\n",
        "  ax = sns.histplot(data=data, x=feature, hue=target, binwidth=binwidth, alpha=0.6);\n",
        "  plt.title(f\"{feature} Distribution by Churn\", fontsize=12, fontweight='bold')\n",
        "\n",
        "  # Boxplot\n",
        "  plt.figure(figsize=(7,2))\n",
        "  ax = sns.boxplot(data=data, x=feature, y=target, hue=target, orient='h');\n",
        "  ax.set_xlabel('')\n",
        "  ax.legend_.remove()\n",
        "  plt.title(f\"Boxplot\", fontsize=10, fontweight='bold')\n",
        "\n",
        "  # Boxplot without Outliers\n",
        "  plt.figure(figsize=(7,1))\n",
        "  ax = sns.boxplot(data=data, x=feature, y=target, hue=target, orient='h', showfliers=False);\n",
        "  ax.set_xlabel('')\n",
        "  ax.legend_.remove()\n",
        "  plt.title(f\"OUTLIERS HIDDEN\", fontsize=9, fontweight='bold')\n",
        "\n",
        "  # Show plots\n",
        "  plt.show()\n",
        "\n",
        "  # Descriptive Stats\n",
        "  print('\\n')\n",
        "  display(data.groupby(target)[feature].describe())\n",
        "  print('\\n')"
      ],
      "metadata": {
        "id": "bVmUDRp3oOO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define variables and call view_distributions\n",
        "data = Superstore_Churn_DF\n",
        "target = 'Churn'\n",
        "\n",
        "# Update this for each feature\n",
        "feature = 'Transactions'\n",
        "\n",
        "# Leave binwidth None, then adjust it to fit the data if desired\n",
        "binwidth = 1\n",
        "\n",
        "# Call the above-defined function\n",
        "view_distributions(data, feature, binwidth)"
      ],
      "metadata": {
        "id": "9RKx9V1xox72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** The upper quartiles of Non-Churners tend to have more transactions. The lower quartiles have only 1 or 2, which is the same for Churners."
      ],
      "metadata": {
        "id": "TMLq5ERuslg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature = 'Avg_Quantity'\n",
        "binwidth = 1\n",
        "view_distributions(data, feature, binwidth)"
      ],
      "metadata": {
        "id": "xMo-s85opI4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE**: Churners tend to purchase in lower quantities."
      ],
      "metadata": {
        "id": "K_Fovmtjt7m4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature = 'Avg_Sales'\n",
        "binwidth = 500\n",
        "view_distributions(data, feature, binwidth)"
      ],
      "metadata": {
        "id": "zc_yNHQ3848t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "73omDHIc846Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A_Jp5ClF842e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sowMP4NF84z4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_WlQOmI-84xT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HomDtAx584uZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xjDkoPwi84mp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Date Features\n",
        "1. **Lifespan:** difference between min and max order date\n",
        "1. **Frequency:** avg difference between all order dates\n",
        "1. **Days to Ship:** avg days between order date and ship date\n",
        "1. **Recency:** difference between max order date and target date 2023-01-01"
      ],
      "metadata": {
        "id": "xNDGl1qdPEyi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "customer_date_features = transaction_features.groupby('Customer ID').agg(\n",
        "    Lifespan=('Order Date', lambda x: (x.max() - x.min()).days),\n",
        "    Frequency=('Order Date', lambda x: int(np.mean(np.diff(x.sort_values()).astype('timedelta64[D]').astype(int))) if len(x) > 1 else 0),\n",
        "    Days_to_Ship=('Order Date', lambda x: np.mean((transaction_features.loc[x.index,'Ship Date'] - transaction_features.loc[x.index,'Order Date']).dt.days)),\n",
        "    Recency=('Order Date', lambda x: (pd.to_datetime('2023-01-01') - x.max()).days)\n",
        ")\n",
        "\n",
        "# Handle potential errors (e.g., a single order date)\n",
        "customer_date_features['Frequency'] = customer_date_features['Frequency'].fillna(0)\n",
        "customer_date_features['Days_to_Ship'] = customer_date_features['Days_to_Ship'].fillna(0)\n",
        "\n",
        "# Display updated dataframe (optional)\n",
        "customer_date_features.sample(25)"
      ],
      "metadata": {
        "id": "9etBf9ssPEH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customer_date_features.info()"
      ],
      "metadata": {
        "id": "217pMiAPPD8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customer_date_features.describe()"
      ],
      "metadata": {
        "id": "Sm43H5OCVM0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combine Numeric and Date Features"
      ],
      "metadata": {
        "id": "3bAfqHmuSvrf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Superstore_Churn_DF = Superstore_Churn_DF.merge(customer_date_features, on='Customer ID', how='left')\n",
        "Superstore_Churn_DF.head(12)"
      ],
      "metadata": {
        "id": "gPPaqtA7PD5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explore Date Features"
      ],
      "metadata": {
        "id": "MsHkQCZ7w456"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue using the above-defined function, repeated here for ease of memory\n",
        "# Define function to view feature distributions and statistics, grouped by target variable\n",
        "def view_distributions(data, feature, binwidth):\n",
        "\n",
        "  # Histplot\n",
        "  plt.figure(figsize=(7,3))\n",
        "  ax = sns.histplot(data=data, x=feature, hue=target, binwidth=binwidth, alpha=0.6);\n",
        "  plt.title(f\"{feature} Distribution by Churn\", fontsize=12, fontweight='bold')\n",
        "\n",
        "  # Boxplot\n",
        "  plt.figure(figsize=(7,2))\n",
        "  ax = sns.boxplot(data=data, x=feature, y=target, hue=target, orient='h');\n",
        "  ax.set_xlabel('')\n",
        "  ax.legend_.remove()\n",
        "  plt.title(f\"Boxplot\", fontsize=10, fontweight='bold')\n",
        "\n",
        "  # Boxplot without Outliers\n",
        "  plt.figure(figsize=(7,1))\n",
        "  ax = sns.boxplot(data=data, x=feature, y=target, hue=target, orient='h', showfliers=False);\n",
        "  ax.set_xlabel('')\n",
        "  ax.legend_.remove()\n",
        "  plt.title(f\"OUTLIERS HIDDEN\", fontsize=9, fontweight='bold')\n",
        "\n",
        "  # Show plots\n",
        "  plt.show()\n",
        "\n",
        "  # Descriptive Stats\n",
        "  print('\\n')\n",
        "  display(data.groupby(target)[feature].describe())\n",
        "  print('\\n')"
      ],
      "metadata": {
        "id": "uYOG9VStwtwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use this format to call the function\n",
        "# Define variables and call view_distributions\n",
        "data = Superstore_Churn_DF\n",
        "target = 'Churn'\n",
        "\n",
        "# Update this for each feature\n",
        "feature = 'Lifespan'\n",
        "\n",
        "# Leave binwidth None, then adjust it to fit the data if desired\n",
        "binwidth = None\n",
        "\n",
        "# Call the above-defined function\n",
        "view_distributions(data, feature, binwidth)"
      ],
      "metadata": {
        "id": "SgpbTJWPwts9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature = ''\n",
        "\n",
        "# Leave binwidth None, then adjust it to fit the data if desired\n",
        "binwidth = None\n",
        "\n",
        "# Call the above-defined function\n",
        "view_distributions(data, feature, binwidth)"
      ],
      "metadata": {
        "id": "7L2n9dBIwtp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2Pwg0mpbwtm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check for Multicollinearity"
      ],
      "metadata": {
        "id": "nalE2m7wLVrt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the correlation matrix\n",
        "corr = Superstore_Churn_DF.corr(method='pearson')\n",
        "\n",
        "# Create a mask to hide the upper triangle\n",
        "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
        "\n",
        "# Set up the plot\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.title(\"Correlation Heatmap\", fontsize=18, fontweight='bold')\n",
        "\n",
        "# Draw the heatmap\n",
        "ax = sns.heatmap(\n",
        "    corr,\n",
        "    mask=mask,\n",
        "    cmap=cpd,\n",
        "    vmin=-1,\n",
        "    vmax=1,\n",
        "    annot=True,\n",
        "    fmt=\".2f\",                  # Format annotations to 2 decimal places\n",
        "    annot_kws={\"size\": 10},      # Optional: Adjust annotation font size\n",
        "    cbar_kws={\"shrink\": 0.8}     # Optional: Make the colorbar a little smaller\n",
        ")\n",
        "\n",
        "# Improve layout\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "p1c7l7-kLVQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTES:**\n",
        "\n",
        "None are above 0.8.\n",
        "\n",
        "These are above 0.7. We may want to remove one of these pairs in a next iteration:\n",
        "  - Avg_Ship_Cost : Avg_Sales = .79\n",
        "  - Total_Profit : Avg_Profit = .77\n",
        "  - Frequency : Lifespan = .77"
      ],
      "metadata": {
        "id": "K5PX2sovMgtE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Final Dataframe for Machine Learning\n"
      ],
      "metadata": {
        "id": "y2JF5XAlw7Nb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Revisit Labels Dataframe\n",
        "Customer_Labels.head(12)"
      ],
      "metadata": {
        "id": "GACuIwQj8lug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge Features Dataframe and Labels Dataframe\n",
        "# Use Customer ID as the common key\n",
        "Superstore_Churn_DF = Customer_Labels.merge(Customer_Features, on='Customer ID')\n",
        "Superstore_Churn_DF.sample(20)"
      ],
      "metadata": {
        "id": "cLpN5nXrw5fw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get an overview of our combined dataframe\n",
        "Superstore_Churn_DF.info()"
      ],
      "metadata": {
        "id": "KGZ97v_X9-13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get numbers of churn vs non-churners\n",
        "Superstore_Churn_DF['Churn'].value_counts()"
      ],
      "metadata": {
        "id": "990vJOUSM6_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get percentages of churn vs non-churners\n",
        "Superstore_Churn_DF['Churn'].value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "vZyTQiWlKo7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning\n",
        "\n",
        "We will check the quality of our feature engineering by creating predictions using an efficient and effective machine learning model:\n",
        "\n",
        "The Random Forest Classifier from Scikit Learn"
      ],
      "metadata": {
        "id": "l_6pOFnnnUqK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Take our prepared dataframe and create X as the features set and y as the labels\n",
        "X = Superstore_Churn_DF.drop(columns=['Churn'])\n",
        "y = Superstore_Churn_DF['Churn']"
      ],
      "metadata": {
        "id": "ZH0LFXje-qfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preview the features we'll use for machine learning\n",
        "X.head(12)"
      ],
      "metadata": {
        "id": "iOG5OGcD-_a2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preview the labels we'll use for machine learning\n",
        "y.head(12)"
      ],
      "metadata": {
        "id": "zplOytqA-_YA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries and packages for prediction and evaluation\n",
        "\n",
        "# For creating train/test splits\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# For the Random Forest Classifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# For evaluating a model's predictive performance\n",
        "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, confusion_matrix\n"
      ],
      "metadata": {
        "id": "LPmrmqRyvJ0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a train / test split, with 30% of the data for test.\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# See the shape of each split compared to the total records: the number and proportion of train and test features and their labels\n",
        "print(f'Total Records: {len(y)}')\n",
        "print(f'Train Split: {X_train.shape[0]} Records, {len(y_train)} Labels = {round(len(y_train)/len(y), 4) * 100}%')\n",
        "print(f'Test Split: {X_test.shape[0]} Records, {len(y_test)} Labels = {round(len(y_test)/len(y), 4) * 100}%')\n",
        "\n",
        "# Preview the training data\n",
        "X_train.head()"
      ],
      "metadata": {
        "id": "LLkMA_HYVA6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict churn using the Random Forest classification model from scikit learn\n",
        "\n",
        "# Set Random Forest classifier as the algorithm for this prediction\n",
        "algorithm = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Train a prediction model by fitting the algorithm to the training set\n",
        "model = algorithm.fit(X_train, y_train)\n",
        "\n",
        "# Use the trained model to make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print('Predictions Complete\\n')\n",
        "\n",
        "# Dataframe of predicted churn probabilities and churn predictions (0 or 1) per customer\n",
        "results_df = X_test.copy()\n",
        "results_df['churn'] = y_test\n",
        "results_df['predicted_probability'] = model.predict_proba(X_test)[:, 1]\n",
        "results_df['prediction'] = y_pred\n",
        "\n",
        "results_df.sample(30)"
      ],
      "metadata": {
        "id": "wJDNhPXR_aYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning Prediction Performance Metrics"
      ],
      "metadata": {
        "id": "t6tgiDpup_hZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Report the accuracy, precision, and recall scores of the model\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred) * 100\n",
        "precision = precision_score(y_test, y_pred) * 100\n",
        "recall = recall_score(y_test, y_pred) * 100\n",
        "\n",
        "print('RESULTS')\n",
        "print(f'Accuracy: \\t{accuracy:.3f}%')\n",
        "print(f'Precision: \\t{precision:.3f}%')\n",
        "print(f'Recall: \\t{recall:.3f}%')"
      ],
      "metadata": {
        "id": "qND5-lVzuaxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a better custom Confusion Matrix\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred) * 100\n",
        "precision = precision_score(y_test, y_pred) * 100\n",
        "recall = recall_score(y_test, y_pred) * 100\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "# Normalize true, pred, or all\n",
        "cm_norm = confusion_matrix(y_test, y_pred, normalize='all')\n",
        "cm_colors = sns.color_palette(['gainsboro', 'cornflowerblue'])\n",
        "\n",
        "# axis labels for the confusion matrix plot\n",
        "cm_y_labels = ['0','1'] # column labels\n",
        "cm_x_labels = ['0','1'] # row labels\n",
        "\n",
        "# Confusion matrix labels\n",
        "# Review and update to match the appropriate labels for your data set\n",
        "group_names = ['True Negative', 'False Positive', 'False Negative', 'True Positive']\n",
        "group_counts = ['{0:0.0f}'.format(value) for value in cm.flatten()]\n",
        "group_percentages = ['{0:.2%}'.format(value) for value in cm_norm.flatten()]\n",
        "group_labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in\n",
        "          zip(group_names, group_percentages, group_counts)]\n",
        "group_labels = np.asarray(group_labels).reshape(2,2)\n",
        "\n",
        "# Begin plot setup\n",
        "fig, ax = plt.subplots(figsize=(4.2, 4.2))\n",
        "\n",
        "# Heatmap\n",
        "sns.heatmap(np.eye(2), annot=group_labels, annot_kws={'size': 11}, fmt='',\n",
        "            cmap=cm_colors, cbar=False,\n",
        "            yticklabels=cm_y_labels, xticklabels=cm_x_labels, ax=ax)\n",
        "\n",
        "# Axis elements\n",
        "ax.xaxis.tick_top()\n",
        "ax.xaxis.set_label_position('top')\n",
        "ax.tick_params(labelsize=10, length=0)\n",
        "ax.set_xlabel('Predicted Values', size=10)\n",
        "ax.set_ylabel('Actual Values', size=10)\n",
        "\n",
        "# Position group labels and set colors\n",
        "for text_elt, group_label in zip(ax.texts, group_labels):\n",
        "    ax.text(*text_elt.get_position(), '\\n', color=text_elt.get_color(),\n",
        "            ha='center', va='top')\n",
        "\n",
        "# Title for each plot\n",
        "# Adjust pad to provide room for the score report below title and above confusion matrix plot\n",
        "plt.title(f'{model}', pad=80, loc='left', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Score reports beneath each title\n",
        "# Adjust x and y to fit report\n",
        "plt.figtext(0.21, 0.81, f'{accuracy:.3f}%  Accuracy\\n{precision:.3f}%  Precision\\n{recall:.3f}%  Recall', wrap=True, ha='left', fontsize=10)\n",
        "\n",
        "# Disply the plot!\n",
        "plt.tight_layout()\n",
        "plt.subplots_adjust(left=0.2)\n",
        "print('\\n') # Add a blank line for improved spacing\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4oS2VGND28NY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Importances\n",
        "\n",
        "An approximate measure of relevance for each feature: The proportional influence each feature had in the prediction process.\n",
        "\n"
      ],
      "metadata": {
        "id": "WceRXIAEqPmF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get feature importances from the trained RandomForestClassifier model\n",
        "feature_importances = model.feature_importances_\n",
        "\n",
        "# Create a DataFrame to store feature names and their importances\n",
        "feature_importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importances})\n",
        "\n",
        "# Sort the DataFrame by importance in descending order\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Make Feature the new index\n",
        "feature_importance_df = feature_importance_df.set_index('Feature')\n",
        "\n",
        "# Print the features and their importances\n",
        "print(\"Feature Importances:\")\n",
        "feature_importance_df\n"
      ],
      "metadata": {
        "id": "e8CcqGJ2LCLL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}